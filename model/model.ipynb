{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meanSquared is a metric that to reach machine learning models result. \n",
    "# Mean Squared Error: It is a result like (actual value - predict value)^2\n",
    "def meanSquared(y_test, yPredict):\n",
    "    meanSquared = mean_squared_error(y_test, yPredict)\n",
    "    print('Mean Squared Result: ', meanSquared)\n",
    "\n",
    "# meanAbsolute is a metric that to reach machine learning models result.\n",
    "# Mean Absolute Error: It is a result like actual value - predict value\n",
    "def meanAbsolute(y_test, yPredict):\n",
    "    meanAbsolute = mean_absolute_error(y_test, yPredict)\n",
    "    print('Mean Absolute Result: ', meanAbsolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoking dataset with pandas library in here\n",
    "projectDataset = pd.read_excel('ProjectDataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleNo</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1415.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>-40.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-6</td>\n",
       "      <td>53</td>\n",
       "      <td>42.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>70</td>\n",
       "      <td>-23.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>28</td>\n",
       "      <td>-9</td>\n",
       "      <td>-20</td>\n",
       "      <td>98</td>\n",
       "      <td>1233.837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SampleNo  x1  x2  x3  x4  x5  x6         Y\n",
       "0         1  19  30   9  24   5   2  1415.924\n",
       "1         2  33  50   6  53  20  63   -40.440\n",
       "2         3  22  49   0  16  -6  53    42.548\n",
       "3         4  38   6  22  50  12  70   -23.640\n",
       "4         5  11  40  28  -9 -20  98  1233.837"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projectDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SampleNo is an index of the dataset's rows so we can drop it.\n",
    "projectDataset = projectDataset.drop(labels='SampleNo',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1,x2,x3,x4,x5,x6 is a features and Y is a label in this algorithm so we can split it this values for model.\n",
    "allXValues = projectDataset[['x1','x2','x3','x4','x5','x6']].values\n",
    "yValues = projectDataset['Y'].values\n",
    "xValues = allXValues[:99,:]\n",
    "yValues = yValues[:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split is a function that split our features and labels, in here we split datas as %20 test and %80 train.\n",
    "x_train,x_test,y_train,y_test = train_test_split(xValues,yValues,test_size = 0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.755\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.739\n",
      "Method:                 Least Squares   F-statistic:                              45.69\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    2.83e-21\n",
      "Time:                        22:56:24   Log-Likelihood:                         -713.06\n",
      "No. Observations:                  79   AIC:                                      1436.\n",
      "Df Residuals:                      74   BIC:                                      1448.\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           115.5669     14.446      8.000      0.000      86.783     144.350\n",
      "x2           -60.1803     16.139     -3.729      0.000     -92.339     -28.022\n",
      "x3           125.2624     21.202      5.908      0.000      83.016     167.509\n",
      "x4             2.0641      8.939      0.231      0.818     -15.747      19.875\n",
      "x5          -113.5029     14.966     -7.584      0.000    -143.323     -83.683\n",
      "x6           -11.5514      7.921     -1.458      0.149     -27.335       4.232\n",
      "==============================================================================\n",
      "Omnibus:                       18.776   Durbin-Watson:                   1.619\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.091\n",
      "Skew:                           1.019   Prob(JB):                     2.16e-06\n",
      "Kurtosis:                       4.943   Cond. No.                     5.17e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The smallest eigenvalue is 1.48e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# OLS is a function for checking model's fitting.\n",
    "# In here we can say that our x4 values's P values is 0.818 so the rule is if variable's P-value is higher than 0.05 than we\n",
    "# should remove it and fit the model again.\n",
    "model = sm.OLS(y_train,x_train).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.755\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.739\n",
      "Method:                 Least Squares   F-statistic:                              45.69\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    2.83e-21\n",
      "Time:                        22:56:24   Log-Likelihood:                         -713.06\n",
      "No. Observations:                  79   AIC:                                      1436.\n",
      "Df Residuals:                      74   BIC:                                      1448.\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           117.6310     18.793      6.259      0.000      80.185     155.077\n",
      "x2           -60.1803     16.139     -3.729      0.000     -92.339     -28.022\n",
      "x3           125.2624     21.202      5.908      0.000      83.016     167.509\n",
      "x4          -111.4388     19.977     -5.578      0.000    -151.244     -71.634\n",
      "x5           -11.5514      7.921     -1.458      0.149     -27.335       4.232\n",
      "==============================================================================\n",
      "Omnibus:                       18.776   Durbin-Watson:                   1.619\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.091\n",
      "Skew:                           1.019   Prob(JB):                     2.16e-06\n",
      "Kurtosis:                       4.943   Cond. No.                         6.75\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# For instance over there, we use \"xValues[:,[0,1,2,4,5]]\" for drop x4 values and resplit values after that, we can fit\n",
    "# the model again\n",
    "# As you can see in the new result x5 value's P-value is equal to 0.149 so we can remove this column again and re-run the model.\n",
    "XValues = xValues[:,[0,1,2,4,5]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "model = sm.OLS(y_train,x_train).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.748\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.735\n",
      "Method:                 Least Squares   F-statistic:                              55.74\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    9.94e-22\n",
      "Time:                        22:56:24   Log-Likelihood:                         -714.18\n",
      "No. Observations:                  79   AIC:                                      1436.\n",
      "Df Residuals:                      75   BIC:                                      1446.\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           112.9541     18.656      6.055      0.000      75.789     150.119\n",
      "x2           -67.9608     15.346     -4.429      0.000     -98.531     -37.390\n",
      "x3           111.0477     18.969      5.854      0.000      73.259     148.837\n",
      "x4          -105.9375     19.764     -5.360      0.000    -145.310     -66.565\n",
      "==============================================================================\n",
      "Omnibus:                       21.158   Durbin-Watson:                   1.570\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.460\n",
      "Skew:                           1.104   Prob(JB):                     1.47e-07\n",
      "Kurtosis:                       5.165   Cond. No.                         3.59\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# In this new model result our all P-value are 0 and our model's R-squared is 0.75 so we can say that our model is working good.\n",
    "XValues = xValues[:,[0,1,2,4]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "model = sm.OLS(y_train,x_train).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use another machine learning tool which is Linear Regression, in fact linear regression really popular regression model\n",
    "# in supervised machine learning area.\n",
    "linearRegression = LinearRegression()\n",
    "linearRegressionPredict = linearRegression.fit(x_train,y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.839\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.799\n",
      "Method:                 Least Squares   F-statistic:                              20.92\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    3.40e-06\n",
      "Time:                        22:56:24   Log-Likelihood:                         -161.54\n",
      "No. Observations:                  20   AIC:                                      331.1\n",
      "Df Residuals:                      16   BIC:                                      335.1\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            84.7109     17.238      4.914      0.000      48.169     121.253\n",
      "x2           -69.0132     10.548     -6.543      0.000     -91.373     -46.653\n",
      "x3            89.0937     17.117      5.205      0.000      52.806     125.381\n",
      "x4          -116.0154     22.639     -5.125      0.000    -164.007     -68.024\n",
      "==============================================================================\n",
      "Omnibus:                        2.669   Durbin-Watson:                   2.143\n",
      "Prob(Omnibus):                  0.263   Jarque-Bera (JB):                1.349\n",
      "Skew:                           0.619   Prob(JB):                        0.510\n",
      "Kurtosis:                       3.291   Cond. No.                         4.65\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# In our model's P-value are looking good and our R-sqaured value is approximately 0.84 so this model is predicting better than\n",
    "# before one.\n",
    "linearRegressionModel = sm.OLS(linearRegressionPredict,x_test)\n",
    "print(linearRegressionModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Result:  3727028.1165636294\n",
      "Mean Absolute Result:  1591.6301943835106\n"
     ]
    }
   ],
   "source": [
    "meanSquared(y_test,linearRegressionPredict)\n",
    "meanAbsolute(y_test,linearRegressionPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cagri\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Another supervised learning algorithm is gradient boosting, gradient boosting is one of the most popular machine learning \n",
    "algorithms for tabular datasets. It is powerful enough to find any nonlinear relationship between your model target and\n",
    "features and has great usability that can deal with missing values, outliers, and high cardinality categorical values\n",
    "on your features without any special treatment.\"\"\"\n",
    "x_train,x_test,y_train,y_test = train_test_split(xValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "gradientBoosted = XGBClassifier()\n",
    "gradientBoostedPredict = gradientBoosted.fit(x_train,y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.397\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.196\n",
      "Method:                 Least Squares   F-statistic:                              1.974\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                       0.141\n",
      "Time:                        22:56:26   Log-Likelihood:                         -135.34\n",
      "No. Observations:                  20   AIC:                                      280.7\n",
      "Df Residuals:                      15   BIC:                                      285.7\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.5550      4.149      0.375      0.713      -7.288      10.398\n",
      "x2             4.6134      2.941      1.569      0.138      -1.655      10.882\n",
      "x3             5.9108      4.917      1.202      0.248      -4.569      16.391\n",
      "x4            -7.1521      3.468     -2.062      0.057     -14.544       0.239\n",
      "x5            -8.7071      4.177     -2.084      0.055     -17.611       0.197\n",
      "x6             1.2080      1.938      0.623      0.542      -2.922       5.339\n",
      "==============================================================================\n",
      "Omnibus:                        2.877   Durbin-Watson:                   2.090\n",
      "Prob(Omnibus):                  0.237   Jarque-Bera (JB):                1.330\n",
      "Skew:                           0.228   Prob(JB):                        0.514\n",
      "Kurtosis:                       1.822   Cond. No.                     1.89e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The smallest eigenvalue is 2.33e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "gradientBoostedModel = sm.OLS(gradientBoostedPredict,x_test)\n",
    "print(gradientBoostedModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cagri\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.755\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.739\n",
      "Method:                 Least Squares   F-statistic:                              45.69\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    2.83e-21\n",
      "Time:                        22:56:27   Log-Likelihood:                         -713.06\n",
      "No. Observations:                  79   AIC:                                      1436.\n",
      "Df Residuals:                      74   BIC:                                      1448.\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           -60.1803     16.139     -3.729      0.000     -92.339     -28.022\n",
      "x2           125.2624     21.202      5.908      0.000      83.016     167.509\n",
      "x3           117.6310     18.793      6.259      0.000      80.185     155.077\n",
      "x4          -229.0698     28.025     -8.174      0.000    -284.910    -173.229\n",
      "x5           -11.5514      7.921     -1.458      0.149     -27.335       4.232\n",
      "==============================================================================\n",
      "Omnibus:                       18.776   Durbin-Watson:                   1.619\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.091\n",
      "Skew:                           1.019   Prob(JB):                     2.16e-06\n",
      "Kurtosis:                       4.943   Cond. No.                         9.52\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "XValues = xValues[:,[1,2,3,4,5]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "gradientBoosted = XGBClassifier()\n",
    "gradientBoostedPredict = gradientBoosted.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "model = sm.OLS(y_train,x_train).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cagri\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.748\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.735\n",
      "Method:                 Least Squares   F-statistic:                              55.74\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    9.94e-22\n",
      "Time:                        22:56:27   Log-Likelihood:                         -714.18\n",
      "No. Observations:                  79   AIC:                                      1436.\n",
      "Df Residuals:                      75   BIC:                                      1446.\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           -67.9608     15.346     -4.429      0.000     -98.531     -37.390\n",
      "x2           111.0477     18.969      5.854      0.000      73.259     148.837\n",
      "x3           112.9541     18.656      6.055      0.000      75.789     150.119\n",
      "x4          -218.8916     27.345     -8.005      0.000    -273.365    -164.418\n",
      "==============================================================================\n",
      "Omnibus:                       21.158   Durbin-Watson:                   1.570\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.460\n",
      "Skew:                           1.104   Prob(JB):                     1.47e-07\n",
      "Kurtosis:                       5.165   Cond. No.                         5.14\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# In here when we drop some columns and rerun it, we can reach the 0.75 R-squared result in our algorithm.\n",
    "XValues = xValues[:,[1,2,3,4]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "gradientBoosted = XGBClassifier()\n",
    "gradientBoostedPredict = gradientBoosted.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "model = sm.OLS(y_train,x_train).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Result:  564797.34881235\n",
      "Mean Absolute Result:  399.00464999999997\n"
     ]
    }
   ],
   "source": [
    "meanSquared(y_test,gradientBoostedPredict)\n",
    "meanAbsolute(y_test,gradientBoostedPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree based on working with binary trees, this is really good and easy to understand when we use regression algorithms\n",
    "x_train,x_test,y_train,y_test = train_test_split(xValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "decisionTree = DecisionTreeRegressor(random_state=0)\n",
    "decisionTreePredict = decisionTree.fit(x_train,y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.865\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.820\n",
      "Method:                 Least Squares   F-statistic:                              19.20\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    4.87e-06\n",
      "Time:                        22:56:27   Log-Likelihood:                         -147.44\n",
      "No. Observations:                  20   AIC:                                      304.9\n",
      "Df Residuals:                      15   BIC:                                      309.9\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            46.1979      7.596      6.082      0.000      30.007      62.389\n",
      "x2             8.5750      5.385      1.593      0.132      -2.902      20.052\n",
      "x3            38.0274      9.002      4.224      0.001      18.839      57.216\n",
      "x4            -8.5956      6.349     -1.354      0.196     -22.129       4.938\n",
      "x5           -54.7935      7.649     -7.164      0.000     -71.096     -38.491\n",
      "x6            -5.6292      3.548     -1.587      0.133     -13.192       1.934\n",
      "==============================================================================\n",
      "Omnibus:                        1.214   Durbin-Watson:                   1.800\n",
      "Prob(Omnibus):                  0.545   Jarque-Bera (JB):                0.950\n",
      "Skew:                           0.500   Prob(JB):                        0.622\n",
      "Kurtosis:                       2.625   Cond. No.                     1.89e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The smallest eigenvalue is 2.33e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "decisionTreeModel = sm.OLS(decisionTreePredict,x_test)\n",
    "print(decisionTreeModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.639\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.519\n",
      "Method:                 Least Squares   F-statistic:                              5.309\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                     0.00526\n",
      "Time:                        22:56:27   Log-Likelihood:                         -156.64\n",
      "No. Observations:                  20   AIC:                                      323.3\n",
      "Df Residuals:                      15   BIC:                                      328.3\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            26.5029     18.579      1.427      0.174     -13.097      66.103\n",
      "x2            -3.0792      8.530     -0.361      0.723     -21.261      15.103\n",
      "x3            24.3966     14.262      1.711      0.108      -6.002      54.795\n",
      "x4           -54.1402     18.740     -2.889      0.011     -94.084     -14.197\n",
      "x5             4.2553      5.621      0.757      0.461      -7.726      16.236\n",
      "==============================================================================\n",
      "Omnibus:                        9.950   Durbin-Watson:                   1.318\n",
      "Prob(Omnibus):                  0.007   Jarque-Bera (JB):                7.303\n",
      "Skew:                           1.323   Prob(JB):                       0.0260\n",
      "Kurtosis:                       4.327   Cond. No.                         8.68\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "XValues = xValues[:,[0,1,2,4,5]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "decisionTree = DecisionTreeRegressor(random_state=0)\n",
    "decisionTreePredict = decisionTree.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "decisionTreeModel = sm.OLS(decisionTreePredict,x_test)\n",
    "print(decisionTreeModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.505\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.382\n",
      "Method:                 Least Squares   F-statistic:                              4.087\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                      0.0181\n",
      "Time:                        22:56:27   Log-Likelihood:                         -152.20\n",
      "No. Observations:                  20   AIC:                                      312.4\n",
      "Df Residuals:                      16   BIC:                                      316.4\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            24.6260     12.274      2.006      0.062      -1.393      50.645\n",
      "x2            26.4202     10.826      2.440      0.027       3.471      49.370\n",
      "x3           -29.9465     14.368     -2.084      0.054     -60.405       0.512\n",
      "x4            -4.1343      4.357     -0.949      0.357     -13.370       5.101\n",
      "==============================================================================\n",
      "Omnibus:                       22.545   Durbin-Watson:                   0.986\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.994\n",
      "Skew:                           2.004   Prob(JB):                     1.86e-07\n",
      "Kurtosis:                       7.597   Cond. No.                         7.67\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "XValues = xValues[:,[0,2,4,5]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "decisionTree = DecisionTreeRegressor(random_state=0)\n",
    "decisionTreePredict = decisionTree.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "decisionTreeModel = sm.OLS(decisionTreePredict,x_test)\n",
    "print(decisionTreeModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.416\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.312\n",
      "Method:                 Least Squares   F-statistic:                              4.029\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                      0.0246\n",
      "Time:                        22:56:27   Log-Likelihood:                         -152.13\n",
      "No. Observations:                  20   AIC:                                      310.3\n",
      "Df Residuals:                      17   BIC:                                      313.2\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            17.2911      7.149      2.419      0.027       2.209      32.373\n",
      "x2            12.9142     10.120      1.276      0.219      -8.437      34.265\n",
      "x3           -24.5011     13.539     -1.810      0.088     -53.066       4.064\n",
      "==============================================================================\n",
      "Omnibus:                       36.275   Durbin-Watson:                   1.303\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               89.683\n",
      "Skew:                           2.949   Prob(JB):                     3.35e-20\n",
      "Kurtosis:                      11.535   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "XValues = xValues[:,[0,2,4]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "decisionTree = DecisionTreeRegressor(random_state=0)\n",
    "decisionTreePredict = decisionTree.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "decisionTreeModel = sm.OLS(decisionTreePredict,x_test)\n",
    "print(decisionTreeModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.638\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.597\n",
      "Method:                 Least Squares   F-statistic:                              15.84\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    0.000107\n",
      "Time:                        22:56:27   Log-Likelihood:                         -178.83\n",
      "No. Observations:                  20   AIC:                                      361.7\n",
      "Df Residuals:                      18   BIC:                                      363.6\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           134.7762     24.742      5.447      0.000      82.795     186.757\n",
      "x2           -72.2337     39.160     -1.845      0.082    -154.505      10.038\n",
      "==============================================================================\n",
      "Omnibus:                       10.212   Durbin-Watson:                   2.734\n",
      "Prob(Omnibus):                  0.006   Jarque-Bera (JB):                7.605\n",
      "Skew:                           1.246   Prob(JB):                       0.0223\n",
      "Kurtosis:                       4.706   Cond. No.                         1.59\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "XValues = xValues[:,[0,4]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "decisionTree = DecisionTreeRegressor(random_state=0)\n",
    "decisionTreePredict = decisionTree.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "decisionTreeModel = sm.OLS(decisionTreePredict,x_test)\n",
    "print(decisionTreeModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.764\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.752\n",
      "Method:                 Least Squares   F-statistic:                              61.53\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    2.24e-07\n",
      "Time:                        22:56:27   Log-Likelihood:                         -175.72\n",
      "No. Observations:                  20   AIC:                                      353.4\n",
      "Df Residuals:                      19   BIC:                                      354.4\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           161.1917     20.549      7.844      0.000     118.182     204.201\n",
      "==============================================================================\n",
      "Omnibus:                       12.158   Durbin-Watson:                   2.590\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               10.061\n",
      "Skew:                           1.353   Prob(JB):                      0.00654\n",
      "Kurtosis:                       5.180   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Here is only value for fitting decision tree algorithm and we have 0.76 model score about R-squared.\n",
    "XValues = xValues[:,[0]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "decisionTree = DecisionTreeRegressor(random_state=0)\n",
    "decisionTreePredict = decisionTree.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "decisionTreeModel = sm.OLS(decisionTreePredict,x_test)\n",
    "print(decisionTreeModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Result:  10025627.023127582\n",
      "Mean Absolute Result:  2033.4746125000001\n"
     ]
    }
   ],
   "source": [
    "meanSquared(y_test,decisionTreePredict)\n",
    "meanAbsolute(y_test,decisionTreePredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before the last supervised learning algorithm is Random Forest algorithm, actually this algorithm basically using decision tree \n",
    "# structure and it is eager to use on tabular datasets.\n",
    "x_train,x_test,y_train,y_test = train_test_split(xValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "randomForest = RandomForestRegressor(n_estimators=20,random_state=0)\n",
    "\n",
    "randomForestPredict = randomForest.fit(x_train,y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.862\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.816\n",
      "Method:                 Least Squares   F-statistic:                              18.71\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    5.73e-06\n",
      "Time:                        22:56:27   Log-Likelihood:                         -148.39\n",
      "No. Observations:                  20   AIC:                                      306.8\n",
      "Df Residuals:                      15   BIC:                                      311.8\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            40.8127      7.967      5.123      0.000      23.831      57.794\n",
      "x2             6.5016      5.647      1.151      0.268      -5.536      18.539\n",
      "x3            33.6132      9.442      3.560      0.003      13.488      53.738\n",
      "x4           -11.6800      6.659     -1.754      0.100     -25.874       2.514\n",
      "x5           -52.4927      8.022     -6.544      0.000     -69.591     -35.394\n",
      "x6             1.3278      3.721      0.357      0.726      -6.604       9.260\n",
      "==============================================================================\n",
      "Omnibus:                        1.135   Durbin-Watson:                   1.362\n",
      "Prob(Omnibus):                  0.567   Jarque-Bera (JB):                0.764\n",
      "Skew:                           0.464   Prob(JB):                        0.683\n",
      "Kurtosis:                       2.763   Cond. No.                     1.89e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The smallest eigenvalue is 2.33e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "randomForestModel = sm.OLS(randomForestPredict,x_test)\n",
    "print(randomForestModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.862\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.827\n",
      "Method:                 Least Squares   F-statistic:                              24.95\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    1.05e-06\n",
      "Time:                        22:56:27   Log-Likelihood:                         -149.50\n",
      "No. Observations:                  20   AIC:                                      307.0\n",
      "Df Residuals:                      16   BIC:                                      311.0\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            45.4435      6.707      6.776      0.000      31.226      59.661\n",
      "x2             5.2082      5.777      0.902      0.381      -7.038      17.454\n",
      "x3            39.8113      9.375      4.247      0.001      19.937      59.685\n",
      "x4           -10.4475      5.731     -1.823      0.087     -22.596       1.701\n",
      "x5           -55.8910      8.156     -6.853      0.000     -73.180     -38.602\n",
      "==============================================================================\n",
      "Omnibus:                        0.386   Durbin-Watson:                   1.459\n",
      "Prob(Omnibus):                  0.825   Jarque-Bera (JB):                0.437\n",
      "Skew:                           0.278   Prob(JB):                        0.804\n",
      "Kurtosis:                       2.536   Cond. No.                     1.11e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The smallest eigenvalue is 2.57e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "XValues = xValues[:,[0,1,2,3,4]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "randomForest = RandomForestRegressor(n_estimators=20,random_state=0)\n",
    "\n",
    "randomForestPredict = randomForest.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "randomForestModel = sm.OLS(randomForestPredict,x_test)\n",
    "print(randomForestModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.833\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.803\n",
      "Method:                 Least Squares   F-statistic:                              28.17\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    8.02e-07\n",
      "Time:                        22:56:28   Log-Likelihood:                         -149.98\n",
      "No. Observations:                  20   AIC:                                      306.0\n",
      "Df Residuals:                      17   BIC:                                      308.9\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            46.3771      5.406      8.578      0.000      34.970      57.784\n",
      "x2            34.2342      9.087      3.767      0.002      15.062      53.407\n",
      "x3            -7.1980      4.874     -1.477      0.158     -17.481       3.085\n",
      "x4           -53.5751      8.048     -6.657      0.000     -70.554     -36.596\n",
      "==============================================================================\n",
      "Omnibus:                        5.564   Durbin-Watson:                   1.074\n",
      "Prob(Omnibus):                  0.062   Jarque-Bera (JB):                3.376\n",
      "Skew:                           0.947   Prob(JB):                        0.185\n",
      "Kurtosis:                       3.680   Cond. No.                     5.94e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The smallest eigenvalue is 4.76e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "XValues = xValues[:,[0,2,3,4]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "randomForest = RandomForestRegressor(n_estimators=20,random_state=0)\n",
    "\n",
    "randomForestPredict = randomForest.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "randomForestModel = sm.OLS(randomForestPredict,x_test)\n",
    "print(randomForestModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.811\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.777\n",
      "Method:                 Least Squares   F-statistic:                              24.24\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    2.26e-06\n",
      "Time:                        22:56:28   Log-Likelihood:                         -147.54\n",
      "No. Observations:                  20   AIC:                                      301.1\n",
      "Df Residuals:                      17   BIC:                                      304.1\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            33.4243      5.684      5.881      0.000      21.433      45.416\n",
      "x2            24.9191      8.046      3.097      0.007       7.943      41.895\n",
      "x3           -49.4315     10.765     -4.592      0.000     -72.143     -26.720\n",
      "==============================================================================\n",
      "Omnibus:                        3.573   Durbin-Watson:                   1.067\n",
      "Prob(Omnibus):                  0.168   Jarque-Bera (JB):                2.089\n",
      "Skew:                           0.781   Prob(JB):                        0.352\n",
      "Kurtosis:                       3.263   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# In here we have kind a good model result which is 0.81 R-squared.\n",
    "XValues = xValues[:,[0,2,4]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "randomForest = RandomForestRegressor(n_estimators=20,random_state=0)\n",
    "\n",
    "randomForestPredict = randomForest.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "randomForestModel = sm.OLS(randomForestPredict,x_test)\n",
    "print(randomForestModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Result:  459457.1445903957\n",
      "Mean Absolute Result:  444.1186424999999\n"
     ]
    }
   ],
   "source": [
    "meanSquared(y_test,randomForestPredict)\n",
    "meanAbsolute(y_test,randomForestPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This algorithm is the last machine learning algorithm in that project which is, K-NN algorithm stores all \n",
    "# the available data and classifies a new data point based on the similarity. This means when new data appears then it can\n",
    "# be easily classified into a well suite category by using K- NN algorithm.\n",
    "x_train,x_test,y_train,y_test = train_test_split(xValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "kNeighbours = KNeighborsRegressor()\n",
    "\n",
    "kNeighboursPredict = kNeighbours.fit(x_train,y_train).predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.857\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.810\n",
      "Method:                 Least Squares   F-statistic:                              18.02\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    7.25e-06\n",
      "Time:                        22:56:28   Log-Likelihood:                         -156.51\n",
      "No. Observations:                  20   AIC:                                      323.0\n",
      "Df Residuals:                      15   BIC:                                      328.0\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            47.4542     11.957      3.969      0.001      21.968      72.941\n",
      "x2            18.4591      8.476      2.178      0.046       0.393      36.525\n",
      "x3            42.1301     14.171      2.973      0.009      11.925      72.335\n",
      "x4            -6.6769      9.995     -0.668      0.514     -27.980      14.627\n",
      "x5           -54.1311     12.040     -4.496      0.000     -79.794     -28.468\n",
      "x6             0.2321      5.585      0.042      0.967     -11.673      12.137\n",
      "==============================================================================\n",
      "Omnibus:                        2.419   Durbin-Watson:                   2.231\n",
      "Prob(Omnibus):                  0.298   Jarque-Bera (JB):                1.290\n",
      "Skew:                           0.617   Prob(JB):                        0.525\n",
      "Kurtosis:                       3.161   Cond. No.                     1.89e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The smallest eigenvalue is 2.33e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "kNeighboursModel = sm.OLS(kNeighboursPredict,x_test)\n",
    "print(kNeighboursModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.871\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.838\n",
      "Method:                 Least Squares   F-statistic:                              26.92\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    6.25e-07\n",
      "Time:                        22:56:28   Log-Likelihood:                         -155.61\n",
      "No. Observations:                  20   AIC:                                      319.2\n",
      "Df Residuals:                      16   BIC:                                      323.2\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            53.3137      9.104      5.856      0.000      34.014      72.614\n",
      "x2            15.2327      7.842      1.943      0.070      -1.391      31.856\n",
      "x3            44.7578     12.726      3.517      0.003      17.780      71.736\n",
      "x4            -7.2399      7.779     -0.931      0.366     -23.731       9.251\n",
      "x5           -60.5536     11.071     -5.470      0.000     -84.023     -37.084\n",
      "==============================================================================\n",
      "Omnibus:                        5.304   Durbin-Watson:                   1.514\n",
      "Prob(Omnibus):                  0.070   Jarque-Bera (JB):                3.627\n",
      "Skew:                           1.036   Prob(JB):                        0.163\n",
      "Kurtosis:                       3.236   Cond. No.                     1.11e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The smallest eigenvalue is 2.57e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "XValues = xValues[:,[0,1,2,3,4]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "kNeighbours = KNeighborsRegressor()\n",
    "\n",
    "kNeighboursPredict = kNeighbours.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "kNeighboursModel = sm.OLS(kNeighboursPredict,x_test)\n",
    "print(kNeighboursModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.885\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.856\n",
      "Method:                 Least Squares   F-statistic:                              30.65\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    2.55e-07\n",
      "Time:                        22:56:28   Log-Likelihood:                         -151.29\n",
      "No. Observations:                  20   AIC:                                      310.6\n",
      "Df Residuals:                      16   BIC:                                      314.6\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            59.3492     10.323      5.749      0.000      37.465      81.233\n",
      "x2             1.6917      6.317      0.268      0.792     -11.699      15.082\n",
      "x3            33.3100     10.251      3.249      0.005      11.579      55.041\n",
      "x4           -41.8810     13.558     -3.089      0.007     -70.622     -13.140\n",
      "==============================================================================\n",
      "Omnibus:                        1.113   Durbin-Watson:                   2.569\n",
      "Prob(Omnibus):                  0.573   Jarque-Bera (JB):                0.635\n",
      "Skew:                           0.432   Prob(JB):                        0.728\n",
      "Kurtosis:                       2.875   Cond. No.                         4.65\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "XValues = xValues[:,[0,1,2,4]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "kNeighbours = KNeighborsRegressor()\n",
    "\n",
    "kNeighboursPredict = kNeighbours.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "kNeighboursModel = sm.OLS(kNeighboursPredict,x_test)\n",
    "print(kNeighboursModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.888\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.868\n",
      "Method:                 Least Squares   F-statistic:                              44.81\n",
      "Date:                Sun, 29 May 2022   Prob (F-statistic):                    2.75e-08\n",
      "Time:                        22:56:28   Log-Likelihood:                         -146.82\n",
      "No. Observations:                  20   AIC:                                      299.6\n",
      "Df Residuals:                      17   BIC:                                      302.6\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            51.9292      5.481      9.475      0.000      40.366      63.492\n",
      "x2            17.5419      7.759      2.261      0.037       1.173      33.911\n",
      "x3           -46.5086     10.380     -4.481      0.000     -68.409     -24.609\n",
      "==============================================================================\n",
      "Omnibus:                        0.186   Durbin-Watson:                   1.354\n",
      "Prob(Omnibus):                  0.911   Jarque-Bera (JB):                0.136\n",
      "Skew:                          -0.152   Prob(JB):                        0.934\n",
      "Kurtosis:                       2.735   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# In here we have 3 column variables and our model R-squared value is 0.89 so it is the best algorithm for this dataset.\n",
    "XValues = xValues[:,[0,2,4]]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(XValues,yValues,test_size = 0.2,random_state = 0)\n",
    "\n",
    "kNeighbours = KNeighborsRegressor()\n",
    "\n",
    "kNeighboursPredict = kNeighbours.fit(x_train,y_train).predict(x_test)\n",
    "\n",
    "kNeighboursModel = sm.OLS(kNeighboursPredict,x_test)\n",
    "print(kNeighboursModel.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Result:  799968.398061452\n",
      "Mean Absolute Result:  672.3439799999999\n"
     ]
    }
   ],
   "source": [
    "meanSquared(y_test,kNeighboursPredict)\n",
    "meanAbsolute(y_test,kNeighboursPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResult = dict({\"linearRegression\":linearRegressionModel.fit().rsquared,\"gradientBoosted\":gradientBoostedModel.fit().rsquared,\n",
    "                  \"decisionTree\":decisionTreeModel.fit().rsquared,\"randomForest\":randomForestModel.fit().rsquared,\"kNeighbours\":kNeighboursModel.fit().rsquared})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(modelResult):\n",
    "    modelResult1 = sorted(modelResult.values())\n",
    "    sortedDict = {}\n",
    "\n",
    "    for i in modelResult1:\n",
    "        for k in modelResult.keys():\n",
    "            if modelResult[k] == i:\n",
    "                sortedDict[k] = modelResult[k]\n",
    "                break\n",
    "\n",
    "    print(\"Sorted Values \\n\",sortedDict)\n",
    "\n",
    "    predictModel = max(sortedDict,key = sortedDict.get)\n",
    "\n",
    "    if predictModel == 'linearRegression':\n",
    "        last20Values = allXValues[100:,[0,1,2,4]]\n",
    "        result = linearRegression.predict(last20Values)\n",
    "        print(\"Linear Regression Predict \\n\",linearRegression.predict(last20Values))\n",
    "    elif predictModel == 'gradientBoosted':\n",
    "        last20Values = allXValues[100:,[1,2,3,4]]\n",
    "        result = gradientBoosted.predict(last20Values)\n",
    "        print(\"Gradient Boosted Predict \\n\",gradientBoosted.predict(last20Values))\n",
    "    elif predictModel == 'decisionTree':\n",
    "        last20Values = allXValues[100:,[0]]\n",
    "        result = decisionTree.predict(last20Values)\n",
    "        print(\"Decision Tree Predict \\n\",decisionTree.predict(last20Values))\n",
    "    elif predictModel == 'randomForest':\n",
    "        last20Values = allXValues[100:,[0,2,4]]\n",
    "        result = randomForest.predict(last20Values)\n",
    "        print(\"Random Forest Predict \\n\",randomForest.predict(last20Values))\n",
    "    elif predictModel == 'kNeighbours':\n",
    "        last20Values = allXValues[100:,[0,2,4]]\n",
    "        result = kNeighbours.predict(last20Values)\n",
    "        print(\"K-Neighbours Predict \\n\",kNeighbours.predict(last20Values))\n",
    "    \n",
    "    excelResult = pd.DataFrame(data=result)\n",
    "    writer = pd.ExcelWriter(\"PredictResult.xlsx\")\n",
    "    excelResult.to_excel(writer)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Values \n",
      " {'gradientBoosted': 0.39680689826025606, 'decisionTree': 0.764069512347632, 'randomForest': 0.8105345006015943, 'linearRegression': 0.8394995265227613, 'kNeighbours': 0.8877448395092622}\n",
      "K-Neighbours Predict \n",
      " [3739.1486 1871.3952  226.8818 2337.689   252.6452  482.6996 1562.8828\n",
      " 1936.4234 2722.7184  558.678  6550.9192 4797.6016 1224.936  4736.6352\n",
      " 7363.4032 1352.9968  616.1352 1587.5856 2094.9708  -26.2732]\n"
     ]
    }
   ],
   "source": [
    "prediction(modelResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
